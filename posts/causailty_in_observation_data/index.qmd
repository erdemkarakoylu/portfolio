---
title: "Evaluating causality in observational data"
author: "Erdem Karakoylu"
date: "2022-08-08"
categories: [causality, propensity score, R]
image: "effect-1.webp"
---

## Preamble: Causality in observational data
This post illustrates some ways of inferring causality in observational data. Establishing causality of a treatment or similar intervention is more easily done under conditions where all possible factors that may affect the outcome can be controlled for; what is referred to as Randomized Control Trials (RCT.)

Establishing causal link in observational studies can be quite challenging. This is because there can be many potential confounders, not all of which might be identified. By confounder I mean "a variable whose presence affects the variables being studied so that the results do not reflect the actual relationship" ([*Pourhoseingholi et al. 2012*](https://pubmed.ncbi.nlm.nih.gov/24834204/)*.*)

This project illustrates the use of matching and propensity score to establish a causal link beween treatment and outcome in an observational study by *Lalonde (1986)*; a pdf of the paper is available [here](https://www.researchgate.net/publication/4900843_Evaluating_the_Econometric_Evaluations_of_Training_Programs_with_Experiment_Data). The goal of the study was to evaluate the impact of an employment and training program. The data I use here is a subset of the data generated by this study; it includes 614 observations in total with 10 variables. This data is included in *Matching; one of the* libraries I use for this project. The data is loaded as follows.

```{r, warning=FALSE, message=FALSE}
library(MatchIt)
data(lalonde)
```
The loaded data includes a number of covariates, an outcome variable and a treatment flag indicating whether the subject was part of the control or the treatment group. These variables are named and summarized in the table below.


| Variable    | Summary                         |
|-------------|---------------------------------|
| age^1^      | in floating point years         |
| race^1^     | One of Black, Hispanic, White   |
| educ^1^     | years of schooling              |
| married^1^  | Boolean for marital status      |
| nodegree^1^ | Boolean for high school diploma |
| re74^1^     | real earnings in 1974           |
| re75^1^     | real earnings in 1975           |
| re78^2^     | real earnings in 1978           |
| treat^3^    | Boolean for treatment status    |

For convenience, I one-hot encode the race variable, and cast it in its new format along with the rest of the data in a new table that follows. Note that in the present subset of this data, only black and white subjects were available. I therefore do not include hispanic as a covariate in the analysis that follows. For convenience, I also change the outcome variable, $re78$ to the more meaningful name $outcome$.
```{r}
hispan<-as.numeric(lalonde$race=='hispan')
black<-as.numeric(lalonde$race=='black')
white<-as.numeric(lalonde$race=='white')
age<-lalonde$age
educ<-lalonde$educ
married<-lalonde$married
nodegree<-lalonde$nodegree
re74<-lalonde$re74
re75<-lalonde$re75
treat<-lalonde$treat
outcome<-lalonde$re78
mydata<-cbind(age, educ, married, nodegree, black, white, hispan, 
              re74, re75, treat, outcome)
mydata<-data.frame(mydata)
```
All covariates are expected to be confounders. Thus it is important to evaluate whether the data is balanced between treatment and control groups; i.e. whether the covariates are similarly distributed between the two groups. If they are then the analysis can proceed. Otherwise, the data needs to be balanced. One way to balance data is to use *matching*; another will use something called propensity score. Next, I will illustrate both appraoches.

## Matching
### To match or not to match?

A first step is whether the data on hand is appropriate for causal inferrence, in particular, whether it should be balanced. A commonly used metric to figure out whether balancing the data is required is Standardized Mean Difference ($SMD$), defined as the difference between group means divided by the pooled standard deviation, like so:

$$
SMD = \frac{\bar{X}_{treatment}-\bar{X}_{control}}
{\sqrt{\frac{s^2_{treatment}+s^2_{control}}{2}}}
$$
An easy way to examine covariates is to cast them into what is know as a `Table 1`, after a common pattern in the biomedical research litterature to feature patient attributes in the first table of published papers. The *R* library tableone is commonly used for this purpose, with the added benefit that the SMD is given out of the box as shown below. Here the data is stratified by treatment group and only the covariates are tabulated.
```{r}
library(tableone)

# Make a vector of the variable names to be used
xvars <-c("hispan", "black", "white", "age", "educ", "married", "nodegree", 
              "re74", "re75")
# load to a table 1
table1 <- CreateTableOne(vars=xvars, strata="treat", data=mydata, test=FALSE)
# show table, in particular display SMDs corresponding to each covariate. 
print(table1, smd=TRUE)
```
Note that an alternative would be to conduct two-tailed t-tests to assess difference between group (treated and control) means for each covariate, and evaluate their corresponding p-value. This is however not without drawbacks; most importantly the resulting p-value will depend on the sample size. I therefore use $SMD$ in this post.

By convention, an $SMD$ greater than 0.1 suggest an imbalance with respect to the corresponding covariate. Here $SMD>0.1$ for all covariates except *education*. Treated subjects need each to be match via greedy matching to as close as possible a control subject. Matching between subjects is done on the basis of a distance metric indicating how separated they are in the covariate space. The specific metric used in this case is the **Mahalanobis distance**, which is a kind of standardized difference, computed as follows:
$$d = \sqrt{(X_i-X_j)^T C^{-1} (X_i-X_j) }$$
where $X$ is a covariate, $i$ and $j$ are treated and control subjects, and $C$ is the covariance matrix

```{r, warning=FALSE, message=FALSE}
library(Matching)
# Below M=1 refers to pairwise matching. Even so if "ties" is left as TRUE (default)
# multiple subjects within the tolerance threshold will all be matched. 
# In this case, e.g. not setting ties=TRUE yields 207 pairs, even though there are only # 185 treated subjects.
greedymatch<-Match(Tr=treat, M=1, X=mydata[xvars], ties=FALSE) 
matched<-mydata[unlist(greedymatch[c("index.treated", "index.control")]), ]
```

I create another *Table 1* with the matched data check the SMDs.

```{r}
matchedtab1<-CreateTableOne(vars=xvars, strata="treat", data=matched, test=FALSE)
print(matchedtab1, smd=TRUE)
```
Greedy pairwise matching yields, as expected, a reduced data set with 185 subjects in each group. This time all but the variable $re75$ have corresponding $SMD<0.1$. This is not entirely satisfactory and I will attempt to balance the data set using propensity scores next. Before doing so, however, I do a quick outcome analysis and compare the means of the two groups.

```{r}
# Outcome Analysis:
# Carry a paired t-test on the matched data to get a causal risk difference
treated_outcome<-matched$outcome[matched$treat==1]
control_outcome<-matched$outcome[matched$treat==0]
round(mean(treated_outcome) - mean(control_outcome), digits=2)

#pairwise difference
diff_outcome = treated_outcome - control_outcome


#paired t-test
t.test(diff_outcome)
```
A p-value of .92 suggests the difference is not significant. 

## Propensity score matching

A propensity score denoted here $\pi$ is defined as the probability that a subject $i$ received treatment  conditioned on the covariates $X$. I.e. $\pi_i = P(T=1|X_i)$. A $\pi_i=0.4$ means there's a 40% chance the corresponding subject will receive treatment. Covariates can increase or decrease the probability of receiving treatment. For example, if $X$, simplistically the only covariate, is a boolean variable for smoking and smokers are more likely to get a particular treatment then $P(T=1|X=1) \gt P(T=1|X=0)$.  

Interestingly, two subjects may have the same propensity score in spite of having different covariate values $X$, meaning they are equally likely to receive treatment. Thus reducing the data to a subset of subjects with the same $\pi$ should balance the treated and control groups. In doing so a crucial assumption in causality, *ignorability* i.e. how a subject ended in one or the other group can be safely ignored.
In a randomized trial, the propensity score is known. In an observational study $\pi$ is unknown. However because both $X$ and $T$ are collected, $\pi$ can be estimated. For this I will use a logistic regression model where the covariates are the input and the output is the probability of a subject having received treatment. 

```{r}
psmodel <- glm(treat~hispan+white+black+age+educ+married+
                 nodegree+re74+re75,family=binomial(), data=mydata)
```
The model fit is summarized below.

```{r}
# show fit summary
summary(psmodel)
```
Next I extract the propensity scores from the model object.
```{r}
# create propensity score
pscore<-psmodel$fitted.values
```
Finally, I use the MatchIt package to match subjects based on their propensity scores. Note that I set a seed for reproducibility, since matching randomizes data as a first step.
```{r}
set.seed(42)
m.out<-matchit(treat~hispan+white+black+age+educ+married+
                 nodegree+re74+re75, data=mydata, method="nearest")
```

The matching results are summarized below.
```{r}
# summarize the matching outcome
summary(m.out)
```
The figures below also illustrate the matching outcome.
```{r, message=FALSE}
# propensity score plots
plot(m.out, type="hist")
```
The jitter plot below shows the overlap between matched groups.
```{r, message=FALSE}
plot(m.out, type="jitter")
```