{
  "hash": "69e851acd9c613d43ca6ff7132eb1946",
  "result": {
    "markdown": "---\ntitle: \"Evaluating causality in observational data\"\nauthor: \"Erdem Karakoylu\"\ndate: \"2022-08-08\"\ncategories: [causality, propensity score, R]\nimage: \"effect-1.webp\"\n---\n\n\n## Preamble: Causality in observational data\nThis post illustrates some ways of inferring causality in observational data. Establishing causality of a treatment or similar intervention is more easily done under conditions where all possible factors that may affect the outcome can be controlled for; what is referred to as Randomized Control Trials (RCT.)\n\nEstablishing causal link in observational studies can be quite challenging. This is because there can be many potential confounders, not all of which might be identified. By confounder I mean \"a variable whose presence affects the variables being studied so that the results do not reflect the actual relationship\" ([*Pourhoseingholi et al. 2012*](https://pubmed.ncbi.nlm.nih.gov/24834204/)*.*)\n\nThis project illustrates the use of matching and propensity score to establish a causal link beween treatment and outcome in an observational study by *Lalonde (1986)*; a pdf of the paper is available [here](https://www.researchgate.net/publication/4900843_Evaluating_the_Econometric_Evaluations_of_Training_Programs_with_Experiment_Data). The goal of the study was to evaluate the impact of an employment and training program. The data I use here is a subset of the data generated by this study; it includes 614 observations in total with 10 variables. This data is included in *Matching; one of the* libraries I use for this project. The data is loaded as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MatchIt)\ndata(lalonde)\n```\n:::\n\nThe loaded data includes a number of covariates, an outcome variable and a treatment flag indicating whether the subject was part of the control or the treatment group. These variables are named and summarized in the table below.\n\n\n| Variable    | Summary                         |\n|-------------|---------------------------------|\n| age^1^      | in floating point years         |\n| race^1^     | One of Black, Hispanic, White   |\n| educ^1^     | years of schooling              |\n| married^1^  | Boolean for marital status      |\n| nodegree^1^ | Boolean for high school diploma |\n| re74^1^     | real earnings in 1974           |\n| re75^1^     | real earnings in 1975           |\n| re78^2^     | real earnings in 1978           |\n| treat^3^    | Boolean for treatment status    |\n\nFor convenience, I one-hot encode the race variable, and cast it in its new format along with the rest of the data in a new table that follows. Note that in the present subset of this data, only black and white subjects were available. I therefore do not include hispanic as a covariate in the analysis that follows. For convenience, I also change the outcome variable, $re78$ to the more meaningful name $outcome$.\n\n::: {.cell}\n\n```{.r .cell-code}\nhispan<-as.numeric(lalonde$race=='hispan')\nblack<-as.numeric(lalonde$race=='black')\nwhite<-as.numeric(lalonde$race=='white')\nage<-lalonde$age\neduc<-lalonde$educ\nmarried<-lalonde$married\nnodegree<-lalonde$nodegree\nre74<-lalonde$re74\nre75<-lalonde$re75\ntreat<-lalonde$treat\noutcome<-lalonde$re78\nmydata<-cbind(age, educ, married, nodegree, black, white, hispan, \n              re74, re75, treat, outcome)\nmydata<-data.frame(mydata)\n```\n:::\n\nAll covariates are expected to be confounders. Thus it is important to evaluate whether the data is balanced between treatment and control groups; i.e. whether the covariates are similarly distributed between the two groups. If they are then the analysis can proceed. Otherwise, the data needs to be balanced. One way to balance data is to use *matching*; another will use something called propensity score. Next, I will illustrate both appraoches.\n\n## Matching\n### To match or not to match?\n\nA first step is whether the data on hand is appropriate for causal inferrence, in particular, whether it should be balanced. A commonly used metric to figure out whether balancing the data is required is Standardized Mean Difference ($SMD$), defined as the difference between group means divided by the pooled standard deviation, like so:\n\n$$\nSMD = \\frac{\\bar{X}_{treatment}-\\bar{X}_{control}}\n{\\sqrt{\\frac{s^2_{treatment}+s^2_{control}}{2}}}\n$$\nAn easy way to examine covariates is to cast them into what is know as a `Table 1`, after a common pattern in the biomedical research litterature to feature patient attributes in the first table of published papers. The *R* library tableone is commonly used for this purpose, with the added benefit that the SMD is given out of the box as shown below. Here the data is stratified by treatment group and only the covariates are tabulated.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tableone)\n\n# Make a vector of the variable names to be used\nxvars <-c(\"hispan\", \"black\", \"white\", \"age\", \"educ\", \"married\", \"nodegree\", \n              \"re74\", \"re75\")\n# load to a table 1\ntable1 <- CreateTableOne(vars=xvars, strata=\"treat\", data=mydata, test=FALSE)\n# show table, in particular display SMDs corresponding to each covariate. \nprint(table1, smd=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Stratified by treat\n                       0                 1                 SMD   \n  n                        429               185                 \n  hispan (mean (SD))      0.14 (0.35)       0.06 (0.24)     0.277\n  black (mean (SD))       0.20 (0.40)       0.84 (0.36)     1.668\n  white (mean (SD))       0.66 (0.48)       0.10 (0.30)     1.406\n  age (mean (SD))        28.03 (10.79)     25.82 (7.16)     0.242\n  educ (mean (SD))       10.24 (2.86)      10.35 (2.01)     0.045\n  married (mean (SD))     0.51 (0.50)       0.19 (0.39)     0.719\n  nodegree (mean (SD))    0.60 (0.49)       0.71 (0.46)     0.235\n  re74 (mean (SD))     5619.24 (6788.75) 2095.57 (4886.62)  0.596\n  re75 (mean (SD))     2466.48 (3292.00) 1532.06 (3219.25)  0.287\n```\n:::\n:::\n\nNote that an alternative would be to conduct two-tailed t-tests to assess difference between group (treated and control) means for each covariate, and evaluate their corresponding p-value. This is however not without drawbacks; most importantly the resulting p-value will depend on the sample size. I therefore use $SMD$ in this post.\n\nBy convention, an $SMD$ greater than 0.1 suggest an imbalance with respect to the corresponding covariate. Here $SMD>0.1$ for all covariates except *education*. Treated subjects need each to be match via greedy matching to as close as possible a control subject. Matching between subjects is done on the basis of a distance metric indicating how separated they are in the covariate space. The specific metric used in this case is the **Mahalanobis distance**, which is a kind of standardized difference, computed as follows:\n$$d = \\sqrt{(X_i-X_j)^T C^{-1} (X_i-X_j) }$$\nwhere $X$ is a covariate, $i$ and $j$ are treated and control subjects, and $C$ is the covariance matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Matching)\n# Below M=1 refers to pairwise matching. Even so if \"ties\" is left as TRUE (default)\n# multiple subjects within the tolerance threshold will all be matched. \n# In this case, e.g. not setting ties=TRUE yields 207 pairs, even though there are only # 185 treated subjects.\ngreedymatch<-Match(Tr=treat, M=1, X=mydata[xvars], ties=FALSE) \nmatched<-mydata[unlist(greedymatch[c(\"index.treated\", \"index.control\")]), ]\n```\n:::\n\n\nI create another *Table 1* with the matched data check the SMDs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatchedtab1<-CreateTableOne(vars=xvars, strata=\"treat\", data=matched, test=FALSE)\nprint(matchedtab1, smd=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Stratified by treat\n                       0                 1                 SMD   \n  n                        185               185                 \n  hispan (mean (SD))      0.06 (0.24)       0.06 (0.24)    <0.001\n  black (mean (SD))       0.84 (0.37)       0.84 (0.36)     0.015\n  white (mean (SD))       0.10 (0.30)       0.10 (0.30)     0.018\n  age (mean (SD))        25.36 (8.29)      25.82 (7.16)     0.059\n  educ (mean (SD))       10.45 (1.96)      10.35 (2.01)     0.054\n  married (mean (SD))     0.19 (0.39)       0.19 (0.39)    <0.001\n  nodegree (mean (SD))    0.71 (0.46)       0.71 (0.46)    <0.001\n  re74 (mean (SD))     2159.92 (4240.18) 2095.57 (4886.62)  0.014\n  re75 (mean (SD))     1119.08 (2442.29) 1532.06 (3219.25)  0.145\n```\n:::\n:::\n\nGreedy pairwise matching yields, as expected, a reduced data set with 185 subjects in each group. This time all but the variable $re75$ have corresponding $SMD<0.1$. This is not entirely satisfactory and I will attempt to balance the data set using propensity scores next. Before doing so, however, I do a quick outcome analysis and compare the means of the two groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Outcome Analysis:\n# Carry a paired t-test on the matched data to get a causal risk difference\ntreated_outcome<-matched$outcome[matched$treat==1]\ncontrol_outcome<-matched$outcome[matched$treat==0]\nround(mean(treated_outcome) - mean(control_outcome), digits=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 173.05\n```\n:::\n\n```{.r .cell-code}\n#pairwise difference\ndiff_outcome = treated_outcome - control_outcome\n\n\n#paired t-test\nt.test(diff_outcome)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  diff_outcome\nt = 0.25262, df = 184, p-value = 0.8008\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1178.404  1524.494\nsample estimates:\nmean of x \n 173.0453 \n```\n:::\n:::\n\nA p-value of .92 suggests the difference is not significant. \n\n## Propensity scores\n\n\n\n",
    "supporting": [],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}