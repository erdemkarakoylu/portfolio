{
  "hash": "7ecc80969369427ce08fa6234a41051b",
  "result": {
    "markdown": "---\ntitle: \"Evaluating causality in observational data\"\nauthor: \"Erdem Karakoylu\"\ndate: \"2022-08-08\"\ncategories: [causality, propensity score, R]\nimage: \"effect-1.webp\"\n---\n\n\n## Preamble: Causality in observational data\nThis post illustrates some ways of inferring causality in observational data. Establishing causality of a treatment or similar intervention is more easily done under conditions where all possible factors that may affect the outcome can be controlled for; what is referred to as Randomized Control Trials (RCT.)\n\nEstablishing causal link in observational studies can be quite challenging. This is because there can be many potential confounders, not all of which might be identified. By confounder I mean \"a variable whose presence affects the variables being studied so that the results do not reflect the actual relationship\" ([*Pourhoseingholi et al. 2012*](https://pubmed.ncbi.nlm.nih.gov/24834204/)*.*)\n\nThis project illustrates the use of matching and propensity score to establish a causal link beween treatment and outcome in an observational study by *Lalonde (1986)*; a pdf of the paper is available [here](https://www.researchgate.net/publication/4900843_Evaluating_the_Econometric_Evaluations_of_Training_Programs_with_Experiment_Data). The goal of the study was to evaluate the impact of an employment and training program. The data I use here is a subset of the data generated by this study; it includes 614 observations in total with 10 variables. This data is included in *Matching; one of the* libraries I use for this project. The data is loaded as follows.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(MatchIt)\ndata(lalonde)\n```\n:::\n\nThe loaded data includes a number of covariates, an outcome variable and a treatment flag indicating whether the subject was part of the control or the treatment group. These variables are named and summarized in the table below.\n\n\n| Variable    | Summary                         |\n|-------------|---------------------------------|\n| age^1^      | in floating point years         |\n| race^1^     | One of Black, Hispanic, White   |\n| educ^1^     | years of schooling              |\n| married^1^  | Boolean for marital status      |\n| nodegree^1^ | Boolean for high school diploma |\n| re74^1^     | real earnings in 1974           |\n| re75^1^     | real earnings in 1975           |\n| re78^2^     | real earnings in 1978           |\n| treat^3^    | Boolean for treatment status    |\n\nFor convenience, I one-hot encode the race variable, and cast it in its new format along with the rest of the data in a new table that follows. Note that in the present subset of this data, only black and white subjects were available. I therefore do not include hispanic as a covariate in the analysis that follows. For convenience, I also change the outcome variable, $re78$ to the more meaningful name $outcome$.\n\n::: {.cell}\n\n```{.r .cell-code}\nhispan<-as.numeric(lalonde$race=='hispan')\nblack<-as.numeric(lalonde$race=='black')\nwhite<-as.numeric(lalonde$race=='white')\nage<-lalonde$age\neduc<-lalonde$educ\nmarried<-lalonde$married\nnodegree<-lalonde$nodegree\nre74<-lalonde$re74\nre75<-lalonde$re75\ntreat<-lalonde$treat\noutcome<-lalonde$re78\nmydata<-cbind(age, educ, married, nodegree, black, white, hispan, \n              re74, re75, treat, outcome)\nmydata<-data.frame(mydata)\n```\n:::\n\nAll covariates are expected to be confounders. Thus it is important to evaluate whether the data is balanced between treatment and control groups; i.e. whether the covariates are similarly distributed between the two groups. If they are then the analysis can proceed. Otherwise, the data needs to be balanced. One way to balance data is to use *matching*; another will use something called propensity score. Next, I will illustrate both appraoches.\n\n## Matching\n### To match or not to match?\n\nA first step is whether the data on hand is appropriate for causal inferrence, in particular, whether it should be balanced. A commonly used metric to figure out whether balancing the data is required is Standardized Mean Difference ($SMD$), defined as the difference between group means divided by the pooled standard deviation, like so:\n\n$$\nSMD = \\frac{\\bar{X}_{treatment}-\\bar{X}_{control}}\n{\\sqrt{\\frac{s^2_{treatment}+s^2_{control}}{2}}}\n$$\nAn easy way to examine covariates is to cast them into what is know as a `Table 1`, after a common pattern in the biomedical research litterature to feature patient attributes in the first table of published papers. The *R* library tableone is commonly used for this purpose, with the added benefit that the SMD is given out of the box as shown below. Here the data is stratified by treatment group and only the covariates are tabulated.\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tableone)\n\n# Make a vector of the variable names to be used\nxvars <-c(\"hispan\", \"black\", \"white\", \"age\", \"educ\", \"married\", \"nodegree\", \n              \"re74\", \"re75\")\n# load to a table 1\ntable1 <- CreateTableOne(vars=xvars, strata=\"treat\", data=mydata, test=FALSE)\n# show table, in particular display SMDs corresponding to each covariate. \nprint(table1, smd=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Stratified by treat\n                       0                 1                 SMD   \n  n                        429               185                 \n  hispan (mean (SD))      0.14 (0.35)       0.06 (0.24)     0.277\n  black (mean (SD))       0.20 (0.40)       0.84 (0.36)     1.668\n  white (mean (SD))       0.66 (0.48)       0.10 (0.30)     1.406\n  age (mean (SD))        28.03 (10.79)     25.82 (7.16)     0.242\n  educ (mean (SD))       10.24 (2.86)      10.35 (2.01)     0.045\n  married (mean (SD))     0.51 (0.50)       0.19 (0.39)     0.719\n  nodegree (mean (SD))    0.60 (0.49)       0.71 (0.46)     0.235\n  re74 (mean (SD))     5619.24 (6788.75) 2095.57 (4886.62)  0.596\n  re75 (mean (SD))     2466.48 (3292.00) 1532.06 (3219.25)  0.287\n```\n:::\n:::\n\nNote that an alternative would be to conduct two-tailed t-tests to assess difference between group (treated and control) means for each covariate, and evaluate their corresponding p-value. This is however not without drawbacks; most importantly the resulting p-value will depend on the sample size. I therefore use $SMD$ in this post.\n\nBy convention, an $SMD$ greater than 0.1 suggest an imbalance with respect to the corresponding covariate. Here $SMD>0.1$ for all covariates except *education*. Treated subjects need each to be match via greedy matching to as close as possible a control subject. Matching between subjects is done on the basis of a distance metric indicating how separated they are in the covariate space. The specific metric used in this case is the **Mahalanobis distance**, which is a kind of standardized difference, computed as follows:\n$$d = \\sqrt{(X_i-X_j)^T C^{-1} (X_i-X_j) }$$\nwhere $X$ is a covariate, $i$ and $j$ are treated and control subjects, and $C$ is the covariance matrix\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(Matching)\n# Below M=1 refers to pairwise matching. Even so if \"ties\" is left as TRUE (default)\n# multiple subjects within the tolerance threshold will all be matched. \n# In this case, e.g. not setting ties=TRUE yields 207 pairs, even though there are only # 185 treated subjects.\ngreedymatch<-Match(Tr=treat, M=1, X=mydata[xvars], ties=FALSE) \nmatched<-mydata[unlist(greedymatch[c(\"index.treated\", \"index.control\")]), ]\n```\n:::\n\n\nI create another *Table 1* with the matched data check the SMDs.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmatchedtab1<-CreateTableOne(vars=xvars, strata=\"treat\", data=matched, test=FALSE)\nprint(matchedtab1, smd=TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                      Stratified by treat\n                       0                 1                 SMD   \n  n                        185               185                 \n  hispan (mean (SD))      0.06 (0.24)       0.06 (0.24)    <0.001\n  black (mean (SD))       0.84 (0.37)       0.84 (0.36)     0.015\n  white (mean (SD))       0.10 (0.30)       0.10 (0.30)     0.018\n  age (mean (SD))        25.36 (8.29)      25.82 (7.16)     0.059\n  educ (mean (SD))       10.45 (1.96)      10.35 (2.01)     0.054\n  married (mean (SD))     0.19 (0.39)       0.19 (0.39)    <0.001\n  nodegree (mean (SD))    0.71 (0.46)       0.71 (0.46)    <0.001\n  re74 (mean (SD))     2159.92 (4240.18) 2095.57 (4886.62)  0.014\n  re75 (mean (SD))     1119.08 (2442.29) 1532.06 (3219.25)  0.145\n```\n:::\n:::\n\nGreedy pairwise matching yields, as expected, a reduced data set with 185 subjects in each group. This time all but the variable $re75$ have corresponding $SMD<0.1$. This is not entirely satisfactory and I will attempt to balance the data set using propensity scores next. Before doing so, however, I do a quick outcome analysis and compare the means of the two groups.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# Outcome Analysis:\n# Carry a paired t-test on the matched data to get a causal risk difference\ntreated_outcome<-matched$outcome[matched$treat==1]\ncontrol_outcome<-matched$outcome[matched$treat==0]\nround(mean(treated_outcome) - mean(control_outcome), digits=2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 89.28\n```\n:::\n\n```{.r .cell-code}\n#pairwise difference\ndiff_outcome = treated_outcome - control_outcome\n\n\n#paired t-test\nt.test(diff_outcome)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  diff_outcome\nt = 0.13174, df = 184, p-value = 0.8953\nalternative hypothesis: true mean is not equal to 0\n95 percent confidence interval:\n -1247.709  1426.265\nsample estimates:\nmean of x \n 89.27819 \n```\n:::\n:::\n\nA p-value of .92 suggests the difference is not significant. \n\n## Propensity score matching\n\nA propensity score denoted here $\\pi$ is defined as the probability that a subject $i$ received treatment  conditioned on the covariates $X$. I.e. $\\pi_i = P(T=1|X_i)$. A $\\pi_i=0.4$ means there's a 40% chance the corresponding subject will receive treatment. Covariates can increase or decrease the probability of receiving treatment. For example, if $X$, simplistically the only covariate, is a boolean variable for smoking and smokers are more likely to get a particular treatment then $P(T=1|X=1) \\gt P(T=1|X=0)$.  \n\nInterestingly, two subjects may have the same propensity score in spite of having different covariate values $X$, meaning they are equally likely to receive treatment. Thus reducing the data to a subset of subjects with the same $\\pi$ should balance the treated and control groups. In doing so a crucial assumption in causality, *ignorability* i.e. how a subject ended in one or the other group can be safely ignored.\nIn a randomized trial, the propensity score is known. In an observational study $\\pi$ is unknown. However because both $X$ and $T$ are collected, $\\pi$ can be estimated. For this I will use a logistic regression model where the covariates are the input and the output is the probability of a subject having received treatment. \n\n\n::: {.cell}\n\n```{.r .cell-code}\npsmodel <- glm(treat~hispan+white+black+age+educ+married+\n                 nodegree+re74+re75,family=binomial(), data=mydata)\n```\n:::\n\nThe model fit is summarized below.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# show fit summary\nsummary(psmodel)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nglm(formula = treat ~ hispan + white + black + age + educ + married + \n    nodegree + re74 + re75, family = binomial(), data = mydata)\n\nCoefficients: (1 not defined because of singularities)\n              Estimate Std. Error z value Pr(>|z|)    \n(Intercept) -1.663e+00  9.709e-01  -1.713  0.08668 .  \nhispan      -2.082e+00  3.672e-01  -5.669 1.44e-08 ***\nwhite       -3.065e+00  2.865e-01 -10.699  < 2e-16 ***\nblack               NA         NA      NA       NA    \nage          1.578e-02  1.358e-02   1.162  0.24521    \neduc         1.613e-01  6.513e-02   2.477  0.01325 *  \nmarried     -8.321e-01  2.903e-01  -2.866  0.00415 ** \nnodegree     7.073e-01  3.377e-01   2.095  0.03620 *  \nre74        -7.178e-05  2.875e-05  -2.497  0.01253 *  \nre75         5.345e-05  4.635e-05   1.153  0.24884    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 751.49  on 613  degrees of freedom\nResidual deviance: 487.84  on 605  degrees of freedom\nAIC: 505.84\n\nNumber of Fisher Scoring iterations: 5\n```\n:::\n:::\n\nNext I extract the propensity scores from the model object.\n\n::: {.cell}\n\n```{.r .cell-code}\n# create propensity score\npscore<-psmodel$fitted.values\n```\n:::\n\nFinally, I use the MatchIt package to match subjects based on their propensity scores. Note that I set a seed for reproducibility, since matching randomizes data as a first step.\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42)\nm.out<-matchit(treat~hispan+white+black+age+educ+married+\n                 nodegree+re74+re75, data=mydata, method=\"nearest\")\n```\n:::\n\n\nThe matching results are summarized below.\n\n::: {.cell}\n\n```{.r .cell-code}\n# summarize the matching outcome\nsummary(m.out)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nmatchit(formula = treat ~ hispan + white + black + age + educ + \n    married + nodegree + re74 + re75, data = mydata, method = \"nearest\")\n\nSummary of Balance for All Data:\n         Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance        0.5774        0.1822          1.7941     0.9211    0.3774\nhispan          0.0595        0.1422         -0.3498          .    0.0827\nwhite           0.0973        0.6550         -1.8819          .    0.5577\nblack           0.8432        0.2028          1.7615          .    0.6404\nage            25.8162       28.0303         -0.3094     0.4400    0.0813\neduc           10.3459       10.2354          0.0550     0.4959    0.0347\nmarried         0.1892        0.5128         -0.8263          .    0.3236\nnodegree        0.7081        0.5967          0.2450          .    0.1114\nre74         2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75         1532.0553     2466.4844         -0.2903     0.9563    0.1342\n         eCDF Max\ndistance   0.6444\nhispan     0.0827\nwhite      0.5577\nblack      0.6404\nage        0.1577\neduc       0.1114\nmarried    0.3236\nnodegree   0.1114\nre74       0.4470\nre75       0.2876\n\nSummary of Balance for Matched Data:\n         Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance        0.5774        0.3629          0.9739     0.7566    0.1321\nhispan          0.0595        0.2162         -0.6629          .    0.1568\nwhite           0.0973        0.3135         -0.7296          .    0.2162\nblack           0.8432        0.4703          1.0259          .    0.3730\nage            25.8162       25.3027          0.0718     0.4568    0.0847\neduc           10.3459       10.6054         -0.1290     0.5721    0.0239\nmarried         0.1892        0.2108         -0.0552          .    0.0216\nnodegree        0.7081        0.6378          0.1546          .    0.0703\nre74         2095.5737     2342.1076         -0.0505     1.3289    0.0469\nre75         1532.0553     1614.7451         -0.0257     1.4956    0.0452\n         eCDF Max Std. Pair Dist.\ndistance   0.4216          0.9740\nhispan     0.1568          1.0743\nwhite      0.2162          0.8390\nblack      0.3730          1.0259\nage        0.2541          1.3938\neduc       0.0757          1.2474\nmarried    0.0216          0.8281\nnodegree   0.0703          1.0106\nre74       0.2757          0.7965\nre75       0.2054          0.7381\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       185     185\nUnmatched     244       0\nDiscarded       0       0\n```\n:::\n:::\n\nThe figures below also illustrate the matching outcome.\n\n::: {.cell}\n\n```{.r .cell-code}\n# propensity score plots\nplot(m.out, type=\"hist\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-12-1.png){width=672}\n:::\n:::\n\nThe jitter plot below shows the overlap between matched groups.\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(m.out, type=\"jitter\")\n```\n\n::: {.cell-output-display}\n![](index_files/figure-html/unnamed-chunk-13-1.png){width=672}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\nTo identify the units, use first mouse button; to stop, use second.\n```\n:::\n:::",
    "supporting": [
      "index_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}